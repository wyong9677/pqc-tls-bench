name: pqc-bench-paper

on:
  workflow_dispatch:
    inputs:
      mode:
        description: "smoke=quick; paper=publication-grade"
        required: true
        default: "paper"
        type: choice
        options: ["smoke", "paper"]

jobs:
  bench:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    env:
      IMG_BASE: openquantumsafe/oqs-ossl3:latest
      RESULTS_DIR: results

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python (host)
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Prepare dirs
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${RESULTS_DIR}"

      - name: Pull image and lock digest
        shell: bash
        run: |
          set -euo pipefail
          docker pull "${IMG_BASE}"
          DIGEST="$(docker inspect --format='{{index .RepoDigests 0}}' "${IMG_BASE}")"
          echo "IMG=${DIGEST}" >> "$GITHUB_ENV"
          echo "${DIGEST}" | tee "${RESULTS_DIR}/image_digest.txt"

      - name: Compute RUN_ID + mode knobs
        shell: bash
        run: |
          set -euo pipefail
          TS="$(date -u +'%Y%m%dT%H%M%SZ')"
          SHA="$(git rev-parse --short HEAD 2>/dev/null || true)"
          if [ -n "${SHA}" ]; then RUN_ID="${TS}_${SHA}"; else RUN_ID="${TS}"; fi

          MODE="${{ inputs.mode }}"
          echo "MODE=${MODE}" >> "$GITHUB_ENV"
          echo "RUN_ID=${RUN_ID}" >> "$GITHUB_ENV"
          echo "RUN_DIR=${RESULTS_DIR}/${RUN_ID}" >> "$GITHUB_ENV"
          mkdir -p "${RESULTS_DIR}/${RUN_ID}"

          # unified knobs
          if [ "${MODE}" = "smoke" ]; then
            echo "REPEATS=2" >> "$GITHUB_ENV"
            echo "WARMUP=1" >> "$GITHUB_ENV"
            echo "TIMESEC=5" >> "$GITHUB_ENV"
            echo "N=50" >> "$GITHUB_ENV"
            echo "ATTEMPT_TIMEOUT=2" >> "$GITHUB_ENV"
            echo "BENCH_SECONDS=5" >> "$GITHUB_ENV"
            echo "STRICT=0" >> "$GITHUB_ENV"
          else
            echo "REPEATS=5" >> "$GITHUB_ENV"
            echo "WARMUP=2" >> "$GITHUB_ENV"
            echo "TIMESEC=15" >> "$GITHUB_ENV"
            echo "N=200" >> "$GITHUB_ENV"
            echo "ATTEMPT_TIMEOUT=3" >> "$GITHUB_ENV"
            echo "BENCH_SECONDS=15" >> "$GITHUB_ENV"
            echo "STRICT=1" >> "$GITHUB_ENV"
          fi

      - name: Make scripts executable
        shell: bash
        run: |
          set -euo pipefail
          chmod +x scripts/*.sh || true
          chmod +x scripts/core/*.sh || true
          chmod +x scripts/*.py || true
          chmod +x scripts/run_all.sh 2>/dev/null || true

      - name: Debug list scripts (smoke only)
        if: ${{ inputs.mode == 'smoke' }}
        shell: bash
        run: |
          set -euo pipefail
          echo "=== repo root ==="
          ls -la
          echo "=== scripts/ ==="
          ls -la scripts || true
          echo "=== scripts/core/ ==="
          ls -la scripts/core || true
          echo "=== find run_all ==="
          find . -maxdepth 2 -type f -name "*run_all*" -print || true

      # Preflight: fail fast if provider/baseline broken.
      # Requires scripts/preflight_providers.sh (recommended).
      - name: Preflight (providers + ECDSA/PQC sanity)
        shell: bash
        run: |
          set -euo pipefail
          if [ -f "scripts/preflight_providers.sh" ]; then
            MODE="${MODE}" IMG="${IMG}" RESULTS_DIR="${RESULTS_DIR}" RUN_ID="${RUN_ID}" \
              bash scripts/preflight_providers.sh
          else
            echo "[WARN] scripts/preflight_providers.sh not found; skipping preflight."
          fi

      - name: Run pipeline (prefer run_all.sh, fallback to steps)
        shell: bash
        run: |
          set -euo pipefail
          echo "[INFO] MODE=${MODE}"
          echo "[INFO] IMG=${IMG}"
          echo "[INFO] RESULTS_DIR=${RESULTS_DIR}"
          echo "[INFO] RUN_ID=${RUN_ID}"
          echo "[INFO] RUN_DIR=${RUN_DIR}"

          # Always enforce RUN_ID/RUN_DIR consistency:
          export OUTDIR="${RUN_DIR}"

          if [ -f "scripts/run_all.sh" ]; then
            echo "[INFO] Using single entrypoint: scripts/run_all.sh"
            MODE="${MODE}" IMG="${IMG}" RESULTS_DIR="${RESULTS_DIR}" RUN_ID="${RUN_ID}" RUN_DIR="${RUN_DIR}" OUTDIR="${OUTDIR}" \
              REPEATS="${REPEATS}" WARMUP="${WARMUP}" TIMESEC="${TIMESEC}" \
              N="${N}" ATTEMPT_TIMEOUT="${ATTEMPT_TIMEOUT}" BENCH_SECONDS="${BENCH_SECONDS}" STRICT="${STRICT}" \
              bash scripts/run_all.sh |& tee "${RUN_DIR}/run_all.log"
          else
            echo "[WARN] scripts/run_all.sh not found. Falling back to step-by-step pipeline."

            MODE="${MODE}" IMG="${IMG}" RESULTS_DIR="${RESULTS_DIR}" RUN_ID="${RUN_ID}" OUTDIR="${OUTDIR}" \
              bash scripts/env_info_paper.sh |& tee "${RUN_DIR}/env_info.log"

            MODE="${MODE}" IMG="${IMG}" RESULTS_DIR="${RESULTS_DIR}" RUN_ID="${RUN_ID}" OUTDIR="${OUTDIR}" \
              REPEATS="${REPEATS}" WARMUP="${WARMUP}" TIMESEC="${TIMESEC}" \
              bash scripts/bench_tls_paper.sh |& tee "${RUN_DIR}/tls_throughput.log"

            MODE="${MODE}" IMG="${IMG}" RESULTS_DIR="${RESULTS_DIR}" RUN_ID="${RUN_ID}" OUTDIR="${OUTDIR}" \
              REPEATS="${REPEATS}" WARMUP="${WARMUP}" N="${N}" ATTEMPT_TIMEOUT="${ATTEMPT_TIMEOUT}" \
              bash scripts/bench_tls_latency_paper.sh |& tee "${RUN_DIR}/tls_latency.log"

            MODE="${MODE}" IMG="${IMG}" RESULTS_DIR="${RESULTS_DIR}" RUN_ID="${RUN_ID}" OUTDIR="${OUTDIR}" \
              REPEATS="${REPEATS}" WARMUP="${WARMUP}" BENCH_SECONDS="${BENCH_SECONDS}" STRICT="${STRICT}" \
              bash scripts/bench_sig_paper.sh |& tee "${RUN_DIR}/sig_bench.log"

            python3 scripts/summarize_results.py "${RUN_DIR}" |& tee "${RUN_DIR}/summarize.log"
          fi

      # Minimal integrity checks: smoke must not silently produce zeros.
      - name: Verify outputs (fail fast on nonsense)
        shell: bash
        run: |
          set -euo pipefail
          cd "${RUN_DIR}"

          test -f tls_throughput.csv
          lines="$(wc -l < tls_throughput.csv)"
          [ "${lines}" -ge 2 ] || { echo "bad tls_throughput.csv (too few lines)"; exit 2; }

          test -f tls_latency_summary.csv
          # p50 should not be 0 for real data; if it's 0, the pipeline is broken.
          # Allow smoke to fail here (we WANT to catch broken latency).
          awk -F',' 'NR==2 { if($7==0 || $7=="na") exit 2 } END{ }' tls_latency_summary.csv \
            || { echo "bad tls_latency_summary.csv (p50 is 0/na)"; exit 2; }

          # Signature CSV presence depends on your implementation; keep minimal:
          if [ -f sig_speed.csv ]; then
            echo "[INFO] sig_speed.csv present"
            # if STRICT=1, require at least one PQC row + one baseline
            if [ "${STRICT}" = "1" ]; then
              grep -qiE 'mldsa|falcon' sig_speed.csv || { echo "missing PQC rows in sig_speed.csv"; exit 2; }
              grep -qiE 'ecdsa|ecdsap256' sig_speed.csv || { echo "missing ECDSA baseline in sig_speed.csv"; exit 2; }
            fi
          else
            echo "[WARN] sig_speed.csv not found (signature bench may have produced only logs/raw)."
            if [ "${STRICT}" = "1" ]; then
              echo "STRICT=1 but sig_speed.csv missing"; exit 2
            fi
          fi

          echo "OK: output verification passed."

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pqc-paper-results
          path: results
